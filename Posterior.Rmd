---
title: "Posterior"
author: "Devon"
date: "May 2, 2016"
output: html_document
---


```{r}
library(car)
library(scatterplot3d)
library(lme4)
library(aod)
library(Rcpp)
library(ggplot2)
library(plyr)
library(Rmisc)
library(scales)
library(HSAUR)
library(Hmisc)
library(drc)
library(plot3D)
library(boot)
library(pheatmap)
library(LearnBayes)
library(pbkrtest) 
library(fields)
library(arm)
library(AICcmodavg)

rm(list = ls())

estBetaParams <- function(mu, var) {
  alpha <- ((1 - mu) / var - 1 / mu) * mu ^ 2
  beta <- alpha * (1 / mu - 1)
  return(params = list(alpha = alpha, beta = beta))
}
estBetaParams(.5, 0.05)

<<<<<<< HEAD
Y <- (read.csv("/Users/devonrossman/Desktop/CSVforR/SoySdTrt/CSVFiles/CADnoCON.csv"))
Y3<-subset(Y, !(Y$Diff8=="NA" ) & !(Y$sdtrt=="CON")
=======
Y <- (read.csv("/Users/devonrossman/Desktop/CSVforR/SoySdTrt/CSVFiles/CAD.csv"))
Y3<-subset(Y, !(Y$Diff8=="NA" ) #& !(Y$sdtrt=="CON")
>>>>>>> 7188d287892d16ebc5e69570c902287273bfb9ea
                )

Y3$stcost <- ifelse(Y3$sdtrt == "F", 4, ifelse((Y3$sdtrt =="F+I"), 10, 20))
#Y3up <- rbind(Y3, Y3, Y3, Y3, Y3, Y3, Y3, Y3, Y3, Y3)
Diff<-function(x){
  cry<-(Y3$stcost/(Y3$yield*x))
  diff<-(Y3$RR-cry)
  return(diff)
}
output<-as.data.frame(NULL)
for(i in c(6,10,14)){
DIFF<-Diff(i)
output_i<-cbind.data.frame(Y3, DIFF, i)
output<-rbind.data.frame(output,output_i)
}
output$soycost<-as.numeric(output$i)
output$Diff<-as.numeric(output$DIFF)

binarfun<-function(x)
{
  ifelse(x < 0, 0, ifelse((x > 0), 1, 1))
  }
N<-as.vector(binarfun(output$Diff))
output<-cbind(N, output)
D <-( ddply(output, c("location", "var", "sdtrt", "soycost", "Low5wk", "YL"), summarise,
            count=length(Diff),
               mean = mean(Diff),
            Nmean = mean(N),
               sd   = sd(Diff),
            sdN = sd(N),
               se   = sd / sqrt(count),
            seN = sdN / sqrt(count),
            scale=sd*0.551328895))
#D$N <- ifelse(D$mean < 0, 0, ifelse((D$mean > 0), 1, 1))
D$var <- as.factor(D$var)

m <- glmer(Nmean ~ sdtrt + Low5wk + soycost + (1 | location) + (1 | var), D, binomial
)

#McFaddens Pseudo R-squared
#1 - (Residual variance / Null variance)
1-(729.98/1318.59)
#fit<-predict(m, type=c("response"))
<<<<<<< HEAD
predictwse<-predictSE.merMod(m, D, se.fit = TRUE, type = "link", level=0, print.matrix = FALSE) 
#v1<-rep.int(1, 840)
D1 <- cbind(D, predictwse)
=======
se.fit<-predictSE.merMod(m, D, se.fit = TRUE, type = "response", level=0, print.matrix = FALSE) 
v1<-rep.int(1, 840)
D1 <- cbind(D, se.fit)
>>>>>>> 7188d287892d16ebc5e69570c902287273bfb9ea
D1 <- within(D1, {
  PredictedProb <- plogis(fit)
  LL <- plogis(fit - (1.96 * se.fit))
  UL <- plogis(fit + (1.96 * se.fit))
  }
)
#subD <- expand.grid(sdtrt = c("F", "F+I", "F+I+N"), Low5wk = c(56.6, 59.5 ))
#predictSE.merMod(m, newdata=subD, se.fit = TRUE, type = "response", level=0, print.matrix = FALSE) 
<<<<<<< HEAD

    calcBetaMean <- function(aa, bb) { BetaMean <- (aa)/(aa + bb); return(BetaMean); }
     calcBetaSd   <- function(aa, bb) { BetaSd <- sqrt((aa * bb)/(((aa + bb)^2) * (aa + bb + 1))); return(BetaSd); }
=======
>>>>>>> 7188d287892d16ebc5e69570c902287273bfb9ea

calcPosteriorForProportion <- function(successes, total, a, b)
  {
     # Adapted from triplot() in the LearnBayes package
     # Plot the prior, likelihood and posterior:
     #likelihood_a = successes + 1; likelihood_b = total - successes + 1
     posterior_a = a + successes;  posterior_b = b + total - successes
<<<<<<< HEAD
     #theta = seq(0.005, 0.995, length = 500)
     #prior = dbeta(theta, a, b)
     #likelihood = dbeta(theta, likelihood_a, likelihood_b)
     #posterior  = dbeta(theta, posterior_a, posterior_b)
    #  m = max(c(prior, likelihood, posterior))
=======
     theta = seq(0.005, 0.995, length = 500)
     prior = dbeta(theta, a, b)
     likelihood = dbeta(theta, likelihood_a, likelihood_b)
     posterior  = dbeta(theta, posterior_a, posterior_b)
     m = max(c(prior, likelihood, posterior))
>>>>>>> 7188d287892d16ebc5e69570c902287273bfb9ea
    # plot(theta, posterior, type = "l", ylab = "Density", lty = 2, lwd = 3,
        #  main = paste("beta(", a, ",", b, ") prior, B(", total, ",", successes, ") data,",
         # "beta(", posterior_a, ",", posterior_b, ") posterior"), ylim = c(0, m), col = "red")
    # lines(theta, likelihood, lty = 1, lwd = 3, col = "blue")
    # lines(theta, prior, lty = 3, lwd = 3, col = "green")
    # legend(x=0.8,y=m, c("Prior", "Likelihood", "Posterior"), lty = c(3, 1, 2),
        #  lwd = c(3, 3, 3), col = c("green", "blue", "red"))
     # Print out summary statistics for the prior, likelihood and posterior:
     #calcBetaMode <- function(aa, bb) { BetaMode <- (aa - 1)/(aa + bb - 2); return(BetaMode); }
 
     #prior_mode      <- calcBetaMode(a, b)
     #likelihood_mode <- calcBetaMode(likelihood_a, likelihood_b)
     #posterior_mode  <- calcBetaMode(posterior_a, posterior_b)
     #prior_mean      <- calcBetaMean(a, b)
     #likelihood_mean <- calcBetaMean(likelihood_a, likelihood_b)
     posterior_mean  <- calcBetaMean(posterior_a, posterior_b)
     return(posterior_mean)
     #prior_sd        <- calcBetaSd(a, b)
     #likelihood_sd   <- calcBetaSd(likelihood_a, likelihood_b)
     posterior_sd    <- calcBetaSd(posterior_a, posterior_b)
     return(posterior_sd)
     #print(paste("mode for prior=",prior_mode,", for likelihood=",likelihood_mode,", for posterior=",posterior_mode))
     #print(paste("mean for prior=",prior_mean,", for likelihood=",likelihood_mean,", for posterior=",posterior_mean))
     #print(paste("sd for prior=",prior_sd,", for likelihood=",likelihood_sd,", for posterior=",posterior_sd))
  }

D2<-D1
output<-as.data.frame(NULL)
for(i in D1$PredictedProb){
PROB<-calcPosteriorForProportion(i,1,1,1)
#The desirable beta distribution is alpha=2,beta=2
output_i<-as.data.frame(PROB)
output<-rbind.data.frame(output, output_i)
}
YLplus<-paste(D1$YL, D1$var, D1$sdtrt, D1$soycost)
D1$YLplus<-YLplus
stuff<-as.data.frame(cbind(output$PROB, D1$PredictedProb, D1$N))
rownames(stuff)<-D1$YLplus
colnames(stuff)<-c("Posterior", "Predicted Probability", "Break Even")
pheatmap(stuff, show_rownames = TRUE, show_colnames = TRUE,
         #cluster_rows=hc.rows, 
         clustering_method="average")

D1<-cbind(D1,output)
D1test <-( ddply(D1, c("YL", "sdtrt"), summarise,
               meanN    = mean(D1$N),
               meanposterior = mean(D1$PROB),
               meanProb = mean(D1$PredictedProb),
               sd   = sd(PredictedProb),
            scale=sd*0.551328895))
YLplus<-paste(D1test$YL, D1test$sdtrt)
stuff<-as.data.frame(cbind(D1test$meanposterior, D1test$meanProb, D1test$meanN))
rownames(stuff)<-D1test$YLplus
colnames(stuff)<-c("Posterior", "Predicted Probability", "Break Even")
pheatmap(stuff, show_rownames = TRUE, show_colnames = TRUE,
         #cluster_rows=hc.rows, 
         clustering_method="average")

#output$soycost<-as.numeric(output$i)
#output$Diff<-as.numeric(output$DIFF)
#v1<-rep.int(1, 840)
#v075<-rep.int(0.75, 840)

alfredo<-calcPosteriorForProportion(10, 25, 2, 2)
summary(alfredo)
```

Simplified work?
```{r}
library(car)
library(scatterplot3d)
library(lme4)
library(aod)
library(Rcpp)
library(ggplot2)
library(plyr)
library(Rmisc)
library(scales)
library(HSAUR)
library(Hmisc)
library(drc)
library(plot3D)
library(boot)
library(pheatmap)
library(LearnBayes)
library(pbkrtest) 
library(fields)
library(arm)
library(AICcmodavg)
#install.packages("AICcmodavg")

rm(list = ls())

Y <- (read.csv("/Users/devonrossman/Desktop/CSVforR/SoySdTrt/CSVFiles/CADnoCON.csv"))
Y3<-subset(Y, !(Y$Diff8=="NA" ) & !(Y$sdtrt=="CON")
                )
Y3$stcost <- ifelse(Y3$sdtrt == "F", 4, ifelse((Y3$sdtrt =="F+I"), 10, 20))
Diff<-function(x){
  cry<-(Y3$stcost/(Y3$yield*x))
  diff<-(Y3$RR-cry)
  return(diff)
}
output<-as.data.frame(NULL)
for(i in c(6,10,14)){
DIFF<-Diff(i)
output_i<-cbind.data.frame(Y3, DIFF, i)
output<-rbind.data.frame(output,output_i)
}
output$soycost<-as.numeric(output$i)
output$Diff<-as.numeric(output$DIFF)

binarfun<-function(x)
{
  ifelse(x < 0, 0, ifelse((x > 0), 1, 1))
  }
N<-as.vector(binarfun(output$Diff))
output<-cbind(N, output)
D <-( ddply(output, c("location", "var", "sdtrt", "soycost", "Low5wk", "YL"), summarise,
            count=length(Diff),
               mean = mean(Diff),
            Nmean = mean(N),
               sd   = sd(Diff),
            sdN = sd(N),
               se   = sd / sqrt(count),
            seN = sdN / sqrt(count),
            scale=sd*0.551328895))

    calcBetaMean <- function(aa, bb) { BetaMean <- (aa)/(aa + bb); return(BetaMean); }
     calcBetaSd   <- function(aa, bb) { BetaSd <- sqrt((aa * bb)/(((aa + bb)^2) * (aa + bb + 1))); return(BetaSd); }

calcPosteriorForProportion <- function(successes, total, a, b)
  {  posterior_a = a + successes;  posterior_b = b + total - successes
     posterior_mean  <- calcBetaMean(posterior_a, posterior_b)
     return(posterior_mean)
<<<<<<< HEAD
=======
     prior_sd        <- calcBetaSd(a, b)
     likelihood_sd   <- calcBetaSd(likelihood_a, likelihood_b)
>>>>>>> 7188d287892d16ebc5e69570c902287273bfb9ea
     posterior_sd    <- calcBetaSd(posterior_a, posterior_b)
     return(posterior_sd)
  }

<<<<<<< HEAD
D2<-D
output<-as.data.frame(NULL)
for(i in D2$Nmean)
  {
PROB<-calcPosteriorForProportion(i,1,1,1)
#The desirable beta distribution may be either alpha=2,beta=2 or both equal 1...
output_i<-as.data.frame(PROB)
output<-rbind.data.frame(output, output_i)
}

YLplus<-paste(D2$YL, D2$var, D2$sdtrt, D2$soycost)
D2$YLplus<-YLplus
stuff<-as.data.frame(cbind(output$PROB, D$Nmean))
rownames(stuff)<-D2$YLplus
colnames(stuff)<-c("Posterior", "Actual")
pheatmap(stuff, show_rownames = TRUE, show_colnames = TRUE,
         #cluster_rows=hc.rows, 
         clustering_method="average")

D2<-cbind(D,output)
D1test <-( ddply(D1, c("YL", "sdtrt"), summarise,
               meanN    = mean(D1$N),
               meanposterior = mean(D1$PROB),
               meanProb = mean(D1$PredictedProb),
               sd   = sd(PredictedProb),
            scale=sd*0.551328895))
YLplus<-paste(D1test$YL, D1test$sdtrt)
stuff<-as.data.frame(cbind(D1test$meanposterior, D1test$meanProb, D1test$meanN))
rownames(stuff)<-D1test$YLplus
colnames(stuff)<-c("Posterior", "Predicted Probability", "Break Even")
pheatmap(stuff, show_rownames = TRUE, show_colnames = TRUE,
         #cluster_rows=hc.rows, 
         clustering_method="average")
=======
D2<-D1
output<-as.data.frame(NULL)
for(i in D1$PredictedProb){
         PROB<-calcPosteriorForProportion(i,1,0.75,0.75)
output_i<-cbind.data.frame(D2, PROB)
output<-rbind.data.frame(output,output_i)
}


output$soycost<-as.numeric(output$i)
output$Diff<-as.numeric(output$DIFF)
v1<-rep.int(1, 840)
v075<-rep.int(0.75, 840)
>>>>>>> 7188d287892d16ebc5e69570c902287273bfb9ea

alfredo<-calcPosteriorForProportion(5, 25, 0.5, 0)

summary(alfredo)
```

```



http://a-little-book-of-r-for-bayesian-statistics.readthedocs.io/en/latest/src/bayesianstats.html 

defunct script:

quantile1 <- list(p=0.5, x=0.5)    # we believe the median of the prior is 0.5
quantile2 <- list(p=0.95,x=0.25) # we believe the 95th percentile of the prior is 0.25
quantile3 <- list(p=0.05,x=0.75) # we believe the 5th percentile of the prior is 0.75

findBeta <- function(quantile1,quantile2,quantile3)
  {
     # find the quantiles specified by quantile1 and quantile2 and quantile3
     quantile1_p <- quantile1[[1]]; quantile1_q <- quantile1[[2]]
     quantile2_p <- quantile2[[1]]; quantile2_q <- quantile2[[2]]
     quantile3_p <- quantile3[[1]]; quantile3_q <- quantile3[[2]]

     # find the beta prior using quantile1 and quantile2
     priorA <- beta.select(quantile1,quantile2)
     priorA_a <- priorA[1]; priorA_b <- priorA[2]

     # find the beta prior using quantile1 and quantile3
     priorB <- beta.select(quantile1,quantile3)
     priorB_a <- priorB[1]; priorB_b <- priorB[2]

     # find the best possible beta prior
     diff_a <- abs(priorA_a - priorB_a); diff_b <- abs(priorB_b - priorB_b)
     step_a <- diff_a / 100; step_b <- diff_b / 100
     if (priorA_a < priorB_a) { start_a <- priorA_a; end_a <- priorB_a }
     else                     { start_a <- priorB_a; end_a <- priorA_a }
     if (priorA_b < priorB_b) { start_b <- priorA_b; end_b <- priorB_b }
     else                     { start_b <- priorB_b; end_b <- priorA_b }
     steps_a <- seq(from=start_a, to=end_a, length.out=1000)
     steps_b <- seq(from=start_b, to=end_b, length.out=1000)
     max_error <- 10000000000000000000
     best_a <- 0; best_b <- 0
     for (a in steps_a)
     {
        for (b in steps_b)
        {
           # priorC is beta(a,b)
           # find the quantile1_q, quantile2_q, quantile3_q quantiles of priorC:
           priorC_q1 <- qbeta(c(quantile1_p), a, b)
           priorC_q2 <- qbeta(c(quantile2_p), a, b)
           priorC_q3 <- qbeta(c(quantile3_p), a, b)
           priorC_error <- abs(priorC_q1-quantile1_q) +
                           abs(priorC_q2-quantile2_q) +
                           abs(priorC_q3-quantile3_q)
           if (priorC_error < max_error)
           {
             max_error <- priorC_error; best_a <- a; best_b <- b
           }
       }
    }
    print(paste("The best beta prior has a=",best_a,"b=",best_b))
  }


findBeta(quantile1,quantile2,quantile3)
